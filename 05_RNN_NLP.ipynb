{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with RNN\n",
    "\n",
    "**Tokenization:** Breaking a sentence into single words of or small phrases. \n",
    "\n",
    "**Stemming:**  Breaking the word into its root/basic form. Lafzoon ko tor kr \n",
    "basic form mein lana. ex. jumping=jump\n",
    "\n",
    "**Lemmatization:** Similar to stemming but retain the context. meaning full base form\n",
    "\n",
    "**Transformers:** are the models. use self attention mechanism. eg Bert, gpt-2.\n",
    "\n",
    "**Stop Words:** a, an, the. Words like these are called stop words andn filtered to reduce the data.\n",
    "\n",
    "**Bag of words (BOW):** Frequency of each token.\n",
    "\n",
    "**Term Frequency-Inverse Document Frequency (IF-IDF):** Numerical statistic that reflects \n",
    "the importance of a word or term in the document. Used in text-summarizers. ایک جملے میں کسی بھی لفظ کی کتنی اہمیت ہے۔ \n",
    "\n",
    "**Name Entity Recognition(NER):** Categorizing each word in a sentence. location, codes, \n",
    "names, days, country name etc. eg. Ali works in google. \"Ali\" = name, \"google\" = Organization; \n",
    "\n",
    "**Parts of Speech(POS) Tagging:**Tagging each part of speech in a sentences. \n",
    "\n",
    "**Syntax and passing:** Rules, Principles of natural language. \n",
    "\n",
    "**Sementic Analysis:** Analyzing the meaning of a sentence, slangs of sentence. \n",
    "eg. Apple has high stocks. meaning: apple is a company not fruit in this sentence. \n",
    "\n",
    "**Sentiment Analysis:**\n",
    "\n",
    "**Word Embedding**\n",
    "\n",
    "**Sequence to sequence model:** Used in language translation.\n",
    "\n",
    "**Attention Mechanism:** Is a technique to focus on important/relevent part of a long sentence.\n",
    "\n",
    "**Language model:** suggests or predict next words. example co-pilot.\n",
    "\n",
    "\n",
    "\n",
    "**Long Short Term Memory(LSTM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Sequential data take too much computational power and is too much complex for ANN. A lot of neurons and layers would be needed for sequential data. That's why RNN is used. It solves this drawback of ANN.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

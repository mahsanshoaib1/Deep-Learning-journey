{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <snap style=\"color:#579676\"> Fundamentals of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic concept of deep learning depends on two things: \n",
    "1. Layers\n",
    "2. Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A Deep learning model is a actually a neural network. Neural network consist of layers. Layers contain the neurons.\n",
    "\n",
    "> Each layer is specified to detect a specific thing. For example in an image analysis, lower layers may identify the edges, higher layers may identify complex features.\n",
    "\n",
    "> There are three kind of layer in a model: \n",
    "\n",
    "   1. **Input Layer**: We just give the input\n",
    "   2. **Ouptut layer**: Gives the desired output\n",
    "   3. **Hidden Layers**: Between the input and output layer. These hidden layers actually identify the patterns in data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum layers in a deep learning model are three. Maximum depends upon the complexity of model and data. Each layer contain nodes in it. These nodes are called neurons. All the calculations of model are done in neurons. \n",
    "\n",
    "The data and features are givien in input layer and their weights are assigned in this layer. \n",
    "\n",
    "In hidden layer, the weighted sum of features is calculated and a constant value is added to the sum. The constant value is known as bias or bias term. Then an activation function is applied to the output.\n",
    "\n",
    "In output layer, the output is defined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<snap style=\"color:skyblue\"> Important concepts </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Arrows that connect the layers and the neurons represent weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **A nerual network model designed by someone to solve a problem is called DL Architecture. We don't need to build architecture. Already existing architectures will be use. For example, for text classification BERT is a famous architecture. I can build by own by using CNN and other libraries like open CV. But we use already existing architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Machine learning vs Deep learning: </snap>\n",
    "\n",
    "> Machine learning is actually the statistical algorithms while deep learning is a logical \n",
    "> structure based on human brain. \n",
    "\n",
    "> Deep learning requires much more data than Machine learning. Deep learning is data hungry\n",
    "\n",
    "> Deep learning models needs GPU as complex metrices operations are carried out. Machine \n",
    "> learning can be carried out on CPU\n",
    "\n",
    "> In Deep learning models, training time is very high. \n",
    "\n",
    "> **Feature selection:** DL models autometically extract the relevent features from data. \n",
    "> In ML, we manually  extract feature. \n",
    "\n",
    "> We cant interpret the Dl models. We dont know whats going on in the hidden layers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Number of neurons in different layers </snap>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In input layer, the number of neurons must be equal to the number of features. Each neuron will contain the feature and its weight\n",
    "\n",
    "The number of neurons in hidden layer is a complex calculation and it depends the complexity of data. All the input neurons will be summed in each neuron of hidden layer. Each neuron of hidden layer will get the different weight of each feature. \n",
    "\n",
    "The number of classes or outputs will define the number of neuron in output layer. In a regeression problem, there will be only one neuron. In case or binary, there will be two neurons. In multiclass classification, there will be more than two neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight is the strength of a feature. Bias is simply a constant value added to the weighted sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> How weights and bias is assigned </snap>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all works on supervised machine learning. \n",
    "\n",
    "Initially, during the training of model weights and bias is randomly assigned to the features in forward propagation. Then in backward propagation the weights and bias is assigned to minimize the loss. The point at which the loss is minimum, that weights and bias gets locked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Loss, optimizer </snap>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is the error between the actual and the predicted value. The difference between predicted and actual value.\n",
    "\n",
    "Optimizers are the algorithms that reassign the weights to minimize the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Gradient Descent </snap>\n",
    "\n",
    "The main difference is that how many data points we are covering while epoches loop.\n",
    "\n",
    "Batch GD: All the data points.\n",
    "\n",
    "Stochastic GD: One datapoint at a time. \n",
    "\n",
    "Minibatch GD: specified number of points. batchsize = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Learning Rate schdule </snap>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Local Minima </snap>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Saddle point </snap>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Transfer learning </snap>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <snap style=\"color:red\"> Why Deep learning is getting so famous: </snap>\n",
    "\n",
    "1. DataSets Availability\n",
    "2. Frameworks\n",
    "3. Architectures\n",
    "4. Hardware\n",
    "5. Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
